{"cells": [{"cell_type": "code", "metadata": {"id": "37191876_0.45028406508418284"}, "execution_count": null, "source": ["#| default_exp learner"], "outputs": []}, {"cell_type": "code", "metadata": {"id": "37191876_0.2340540119386587"}, "execution_count": null, "source": ["import pandas as pd, os"], "outputs": []}, {"cell_type": "markdown", "metadata": {"id": "37191876_0.950597837375772"}, "execution_count": null, "source": ["# Learner"], "outputs": []}, {"cell_type": "markdown", "metadata": {"id": "37191876_0.5942750089990925"}, "execution_count": null, "source": ["## Imports"], "outputs": []}, {"cell_type": "code", "metadata": {"id": "37191876_0.3003957456066988"}, "execution_count": null, "source": ["#|export\nimport math,torch,matplotlib.pyplot as plt\nimport fastcore.all as fc\nfrom collections.abc import Mapping\nfrom operator import attrgetter\nfrom functools import partial\nfrom copy import copy\n\nfrom torch import optim\nimport torch.nn.functional as F\nfrom torch.utils.data import default_collate\n\n# from miniai.conv import *\n\nfrom fastprogress import progress_bar,master_bar\nfrom operator import itemgetter"], "outputs": []}, {"cell_type": "code", "metadata": {"id": "37191876_0.6350051715472551"}, "execution_count": null, "source": ["import matplotlib as mpl\nimport torchvision.transforms.functional as TF\nfrom contextlib import contextmanager\nfrom torch import nn,tensor\nfrom datasets import load_dataset,load_dataset_builder\nimport logging "], "outputs": []}, {"cell_type": "code", "metadata": {"id": "37191876_0.9593951832277237"}, "execution_count": null, "source": ["from torch.utils.data.dataloader import DataLoader, Dataset"], "outputs": []}, {"cell_type": "code", "metadata": {"id": "37191876_0.011362711895115396"}, "execution_count": null, "source": ["logging.disable(logging.WARNING)"], "outputs": []}, {"cell_type": "code", "metadata": {"id": "37191876_0.37339659449360196"}, "execution_count": null, "source": ["torch.set_printoptions(precision=2, linewidth=140, sci_mode=False)\ntorch.manual_seed(1)\nmpl.rcParams['image.cmap'] = 'gray'"], "outputs": []}, {"cell_type": "markdown", "metadata": {"id": "37191876_0.7676000120100097"}, "execution_count": null, "source": ["## Dataset"], "outputs": []}, {"cell_type": "code", "metadata": {"id": "37191876_0.09454611511396815"}, "execution_count": null, "source": ["#| export\nclass DataLoaders:\n    def __init__(self, *dls): self.train,self.valid = dls[:2]\n\n    @classmethod\n    def from_dd(cls, dd, batch_size, as_tuple=True, **kwargs):\n        f = collate_dict(dd['train'])\n        return cls(*get_dls(*dd.values(), bs=batch_size, collate_fn=f, **kwargs))"], "outputs": []}, {"cell_type": "code", "metadata": {"id": "37191876_0.23721679488393277"}, "execution_count": null, "source": ["x,y = 'image','label'\nname = \"fashion_mnist\"\ndsd = load_dataset(name)"], "outputs": []}, {"cell_type": "code", "metadata": {"id": "37191876_0.20580423629432398"}, "execution_count": null, "source": ["dsd[\"train\"][x][0]"], "outputs": []}, {"cell_type": "code", "metadata": {"id": "37191876_0.15633071962091827"}, "execution_count": null, "source": ["#| export \ndef inplace(f):\n    def _f(b):\n        f(b)\n        return b\n    return _f"], "outputs": []}, {"cell_type": "code", "metadata": {"id": "37191876_0.05348230204951743"}, "execution_count": null, "source": ["#| export \ndef collate_dict(ds):\n    get = itemgetter(*ds.features)\n    def _f(b): return get(default_collate(b))\n    return _f"], "outputs": []}, {"cell_type": "code", "metadata": {"id": "37191876_0.8512097580182658"}, "execution_count": null, "source": ["@inplace\ndef transformi(b): b[x] = [torch.flatten(TF.to_tensor(o)) for o in b[x]]"], "outputs": []}, {"cell_type": "code", "metadata": {"id": "37191876_0.5107770369427798"}, "execution_count": null, "source": ["bs = 1024\ntds = dsd.with_transform(transformi)"], "outputs": []}, {"cell_type": "code", "metadata": {"id": "37191876_0.7234163145099837"}, "execution_count": null, "source": ["def get_dls(train_ds, valid_ds, bs, **kwargs):\n    return (DataLoader(train_ds, batch_size=bs, shuffle=True, **kwargs),\n            DataLoader(valid_ds, batch_size=bs*2, **kwargs))"], "outputs": []}, {"cell_type": "code", "metadata": {"id": "37191876_0.42311481742008583"}, "execution_count": null, "source": ["dls = DataLoaders.from_dd(tds, bs, num_workers=4)\ndt = dls.train\n"], "outputs": []}, {"cell_type": "code", "metadata": {"id": "37191876_0.6559398707673347"}, "execution_count": null, "source": ["dt.collate_fn"], "outputs": []}, {"cell_type": "code", "metadata": {"id": "37191876_0.6146889137576825"}, "execution_count": null, "source": ["xb,yb = next(iter(dt))\nxb.shape,yb[:10]"], "outputs": []}, {"cell_type": "markdown", "metadata": {"id": "37191876_0.24929738296126813"}, "execution_count": null, "source": ["## Callback "], "outputs": []}, {"cell_type": "code", "metadata": {"id": "37191876_0.7619159675687766"}, "execution_count": null, "source": ["#| export\nclass cb:\n    order = 0\n        "], "outputs": []}, {"cell_type": "code", "metadata": {"id": "37191876_0.5200435491223372"}, "execution_count": null, "source": ["class testcb(cb):\n    def __init__(self):fc.store_attr()\n        \n    def before_fit(self, learn):\n        print(f\"starting fit function\")\n        \n    def after_fit(self, learn):\n        print(f\"ending fit function with loss : {learn.loss}\")"], "outputs": []}, {"cell_type": "code", "metadata": {"id": "37191876_0.6782009507074833"}, "execution_count": null, "source": ["# class testcb1(cb):\n#     def __init__(self):\n#         fc.store_attr()\n#         self.order = -1\n        \n#     def before_fit(self, learn):\n#         print(f\"starting fit function\")\n        \n#     def after_fit(self, learn):\n#         print(f\"ending fit function with loss : {learn.loss}\")"], "outputs": []}, {"cell_type": "code", "metadata": {"id": "37191876_0.9121309226584118"}, "execution_count": null, "source": ["cbs = [ testcb()]"], "outputs": []}, {"cell_type": "code", "metadata": {"id": "37191876_0.9986705462052261"}, "execution_count": null, "source": ["sorted(cbs, key= attrgetter(\"order\"))"], "outputs": []}, {"cell_type": "code", "metadata": {"id": "37191876_0.1580034784771529"}, "execution_count": null, "source": ["if getattr(testcb(), \"before_fit\"): pass"], "outputs": []}, {"cell_type": "code", "metadata": {"id": "37191876_0.7568039998436031"}, "execution_count": null, "source": ["#| export\n\ndef rcb(cbs, method_name, learn):\n    for cb in sorted(cbs, key= attrgetter(\"order\")):\n        method =  getattr(cb, method_name, None )\n        if method : return method(learn)\n        "], "outputs": []}, {"cell_type": "markdown", "metadata": {"id": "37191876_0.11946161980629166"}, "execution_count": null, "source": ["## Learner Framework Basic"], "outputs": []}, {"cell_type": "code", "metadata": {"id": "37191876_0.9143765683728449"}, "execution_count": null, "source": ["#| export \ndef_device = 'mps' if torch.backends.mps.is_available() else 'cuda' if torch.cuda.is_available() else 'cpu'\n\ndef to_device(x, device=def_device):\n    if isinstance(x, torch.Tensor): return x.to(device)\n    if isinstance(x, Mapping): return {k:v.to(device) for k,v in x.items()}\n    return type(x)(to_device(o, device) for o in x)"], "outputs": []}, {"cell_type": "code", "metadata": {"id": "37191876_0.7322874135671991"}, "execution_count": null, "source": ["\nclass learner:\n    \n    def __init__(self, model, dls,loss_func, lr,opt_func=optim.SGD):fc.store_attr()\n    \n    def one_batch(self):\n        x,y = to_device(self.b)\n        self.preds = self.model(x)\n        self.loss = self.loss_func(self.preds, y)\n        if self.model.training: \n            self.loss.backward()\n            self.opt.step()\n            self.opt.zero_grad()\n#         else :\n#             with torch.no_grad():\n#                 self.preds = self.model(b[0])\n            \n        \n    \n    def one_epoch(self, train):\n        self.model.training = train\n        dl = self.dls.train if train else self.dls.valid\n        for self.b in dl:self.one_batch()\n        \n    def fit(self, epochs):\n        self.model = self.model.to(def_device)\n        self.opt = self.opt_func(self.model.parameters(), self.lr)\n        for e in range(epochs):\n            self.one_epoch(True)\n            with torch.no_grad(): self.one_epoch(False)\n                \n            print(f\"epoch {e} loss :{self.loss}\")\n        \n    "], "outputs": []}, {"cell_type": "code", "metadata": {"id": "37191876_0.2099535250721154"}, "execution_count": null, "source": ["m,nh = 28*28,50\nmodel = nn.Sequential(nn.Linear(m,nh), nn.ReLU(), nn.Linear(nh,10))"], "outputs": []}, {"cell_type": "code", "metadata": {"id": "37191876_0.10394377463123283"}, "execution_count": null, "source": ["learn = learner(model, dls, F.cross_entropy, lr=0.2)\nlearn.fit(3)"], "outputs": []}, {"cell_type": "markdown", "metadata": {"id": "37191876_0.3447081405271457"}, "execution_count": null, "source": ["## Flexible Learner"], "outputs": []}, {"cell_type": "code", "metadata": {"id": "37191876_0.0012713444453664735"}, "execution_count": null, "source": ["class ctx_mng():\n    def __init__(self, name):self.name = name\n        \n    def __enter__(self):print(f\"Executing code before {self.name} function\")\n        \n    def __exit__(self, *args,**kwargs):\n        print(f\"Executing code after{self.name} function\")\n   \n    \n\n    "], "outputs": []}, {"cell_type": "code", "metadata": {"id": "37191876_0.7459216311728325"}, "execution_count": null, "source": ["with ctx_mng(\"before\") as ctx:\n    print(\"function\")"], "outputs": []}, {"cell_type": "code", "metadata": {"id": "37191876_0.039239133089991496"}, "execution_count": null, "source": ["class learner:\n    \n    def __init__(self, model, dls,loss_func, lr,cbs ,opt_func=optim.SGD):fc.store_attr()\n    \n    def one_batch(self):\n        x,y = to_device(self.b)\n        with ctx_mng('batch'):\n            self.preds = self.model(x)\n            self.loss = self.loss_func(self.preds, y)\n            if self.model.training: \n                self.loss.backward()\n                self.opt.step()\n                self.opt.zero_grad()\n#         else :\n#             with torch.no_grad():\n#                 self.preds = self.model(b[0])\n            \n        \n    \n    def one_epoch(self, train):\n        self.model.training = train\n        dl = self.dls.train if train else self.dls.valid\n        with ctx_mng('epoch'):\n            for self.b in dl:self.one_batch()\n        \n    def fit(self, epochs):\n        self.model = self.model.to(def_device)\n        self.opt = self.opt_func(self.model.parameters(), self.lr)\n        with ctx_mng('fit'):\n            for e in range(epochs):\n                self.one_epoch(True)\n                with torch.no_grad(): self.one_epoch(False)\n\n                print(f\"epoch {e} loss :{self.loss}\")"], "outputs": []}, {"cell_type": "code", "metadata": {"id": "37191876_0.8111020901034443"}, "execution_count": null, "source": ["m,nh = 28*28,50\nmodel = nn.Sequential(nn.Linear(m,nh), nn.ReLU(), nn.Linear(nh,10))"], "outputs": []}, {"cell_type": "code", "metadata": {"id": "37191876_0.10314892222303307"}, "execution_count": null, "source": ["learn = learner(model, dls, F.cross_entropy, lr=0.2, cbs = [])\nlearn.fit(1)"], "outputs": []}, {"cell_type": "markdown", "metadata": {"id": "37191876_0.04646478507289986"}, "execution_count": null, "source": ["## More Flexible learner "], "outputs": []}, {"cell_type": "code", "metadata": {"id": "37191876_0.7963938537915669"}, "execution_count": null, "source": ["#| export\n\nclass CancelFitException:pass\nclass CancelEpochException:pass\nclass CancelBatchException:pass"], "outputs": []}, {"cell_type": "code", "metadata": {"id": "37191876_0.04200730229416405"}, "execution_count": null, "source": ["\"fit\".title()"], "outputs": []}, {"cell_type": "code", "metadata": {"id": "37191876_0.3603360192465852"}, "execution_count": null, "source": ["#| export\nclass cb_dec:\n    def __init__(self, name):\n        fc.store_attr()\n        \n    def __call__(self, f):\n        def _f(o,*args,**kwargs):\n            try:\n                o.callback(f\"before_{self.name}\")\n                f(o,*args, **kwargs)\n                o.callback(f\"after_{self.name}\")\n            except: globals()[f\"Cancel{self.name.title()}Exception\"]()\n        return _f \n            \n            "], "outputs": []}, {"cell_type": "code", "metadata": {"id": "37191876_0.5717386165294502"}, "execution_count": null, "source": ["#| export \nclass learner:\n    \n    def __init__(self, model, dls,loss_func, lr,cbs=[] ,opt_func=optim.SGD):fc.store_attr()\n    \n    @cb_dec(\"batch\")\n    def one_batch(self):\n        x,y = to_device(self.b)\n        \n        self.preds = self.model(x)\n        self.loss = self.loss_func(self.preds, y)\n        if self.model.training: \n            self.loss.backward()\n            self.opt.step()\n            self.opt.zero_grad()\n#         else :\n#             with torch.no_grad():\n#                 self.preds = self.model(b[0])\n            \n        \n    @cb_dec(\"epoch\")\n    def one_epoch(self, train):\n        self.model.training = train\n        dl = self.dls.train if train else self.dls.valid\n        \n        for self.b in dl:self.one_batch()\n    \n    @cb_dec(\"fit\")\n    def fit(self, epochs):\n        self.model = self.model.to(def_device)\n        self.opt = self.opt_func(self.model.parameters(), self.lr)\n        \n        for e in range(epochs):\n            self.one_epoch(True)\n            with torch.no_grad(): self.one_epoch(False)\n\n            print(f\"epoch {e} loss :{self.loss}\")\n                \n    def callback(self, nm): rcb(self.cbs, nm, self)\n        "], "outputs": []}, {"cell_type": "code", "metadata": {"id": "37191876_0.8987338861029142"}, "execution_count": null, "source": ["# def rcb(cbs, method_name, learn):\n#     for cb in sorted(cbs, key= attrgetter(\"order\")):\n#         try: return getattr(cb, method_name)(learn)\n#         except Exception as e: print(e)"], "outputs": []}, {"cell_type": "code", "metadata": {"id": "37191876_0.7944390471938878"}, "execution_count": null, "source": ["m,nh = 28*28,50\nmodel = nn.Sequential(nn.Linear(m,nh), nn.ReLU(), nn.Linear(nh,10))"], "outputs": []}, {"cell_type": "code", "metadata": {"id": "37191876_0.5323518091956045"}, "execution_count": null, "source": ["learn = learner(model, dls, F.cross_entropy,lr=0.2,cbs = [testcb()])\nlearn.fit(1)"], "outputs": []}, {"cell_type": "markdown", "metadata": {"id": "37191876_0.35685003942269367"}, "execution_count": null, "source": ["## Trainer Learner"], "outputs": []}, {"cell_type": "code", "metadata": {"id": "37191876_0.6446370436246129"}, "execution_count": null, "source": ["#|export\nclass TrainLearner(learner):\n    def predict(self): self.preds = self.model(self.batch[0])\n    def get_loss(self): self.loss = self.loss_func(self.preds, self.batch[1])\n    def backward(self): self.loss.backward()\n    def step(self): self.opt.step()\n    def zero_grad(self): self.opt.zero_grad()"], "outputs": []}, {"cell_type": "code", "metadata": {"id": "37191876_0.313804707507348"}, "execution_count": null, "source": ["m,nh = 28*28,50\nmodel = nn.Sequential(nn.Linear(m,nh), nn.ReLU(), nn.Linear(nh,10))\n\nlearn = TrainLearner(model, dls, F.cross_entropy,lr=0.2,cbs = [testcb()])\nlearn.fit(1)"], "outputs": []}, {"cell_type": "markdown", "metadata": {"id": "37191876_0.5844462368646772"}, "execution_count": null, "source": ["## Momentum Learner\n"], "outputs": []}, {"cell_type": "code", "metadata": {"id": "37191876_0.14525984269147751"}, "execution_count": null, "source": ["#| export \nclass momentumLearner(learner):\n    def __init__(self, model, dls, loss_func, lr=None, cbs=None, opt_func=optim.SGD, mom=0.85):\n        self.mom = mom\n        super().__init__(model, dls, loss_func, lr, cbs, opt_func)\n        \n    def step(self): self.opt.step()\n        \n    def zero_grad(self): \n        with torch.no_grad():\n            for p in self.model.parameters(): p.grad *= self.mom"], "outputs": []}, {"cell_type": "code", "metadata": {"id": "37191876_0.4578557934285843"}, "execution_count": null, "source": ["m,nh = 28*28,50\nmodel = nn.Sequential(nn.Linear(m,nh), nn.ReLU(), nn.Linear(nh,10))\n\nlearn = TrainLearner(model, dls, F.cross_entropy,lr=0.2,cbs = [testcb()])\nlearn.fit(1)"], "outputs": []}, {"cell_type": "markdown", "metadata": {"id": "37191876_0.6823117726933505"}, "execution_count": null, "source": ["## Metrics Callback"], "outputs": []}, {"cell_type": "code", "metadata": {"id": "37191876_0.44694205092551975"}, "execution_count": null, "source": ["from torcheval.metrics import MulticlassAccuracy"], "outputs": []}, {"cell_type": "code", "metadata": {"id": "37191876_0.8914758232251403"}, "execution_count": null, "source": ["ms = [MulticlassAccuracy()]"], "outputs": []}, {"cell_type": "code", "metadata": {"id": "37191876_0.18606945592817148"}, "execution_count": null, "source": ["class Metrics(cb):\n    ...\n\n\n"], "outputs": []}, {"cell_type": "code", "metadata": {"id": "37191876_0.7864655269083212"}, "execution_count": null, "source": ["metricss={}\nmetricss[type(ms[0]).__name__] = ms[0]"], "outputs": []}, {"cell_type": "code", "metadata": {"id": "37191876_0.14231678964527616"}, "execution_count": null, "source": ["metricss"], "outputs": []}, {"cell_type": "code", "metadata": {"id": "37191876_0.633174098644002"}, "execution_count": null, "source": ["#| hide \nimport nbdev; nbdev.nbdev_export()"], "outputs": []}, {"cell_type": "code", "metadata": {"id": "37191876_0.24943944933713236"}, "execution_count": null, "source": [""], "outputs": []}], "metadata": {}, "nbformat": 4, "nbformat_minor": 2}