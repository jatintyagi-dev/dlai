{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f385bfc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ef7c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "import pickle,gzip,math,os,time,shutil,torch,matplotlib as mpl,numpy as np,matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from torch import tensor,nn\n",
    "import torch.nn.functional as F\n",
    "import fastcore.all as fc\n",
    "from functools import partial\n",
    "from fastcore.test import test_close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac2d04da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce2f947",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b73535fc",
   "metadata": {},
   "source": [
    "# Mini Batch Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e1395e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "torch.set_printoptions(precision=2, linewidth=140, sci_mode=False)\n",
    "torch.manual_seed(1)\n",
    "mpl.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "path_data = Path('../../course22p2/data')\n",
    "path_gz = path_data/'mnist.pkl.gz'\n",
    "with gzip.open(path_gz, 'rb') as f: ((x_train, y_train), (x_valid, y_valid), _) = pickle.load(f, encoding='latin-1')\n",
    "x_train, y_train, x_valid, y_valid = map(tensor, [x_train, y_train, x_valid, y_valid])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "417e8c8c",
   "metadata": {},
   "source": [
    "## Datasets and DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b49328ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def dl(x_train, bs = 64):\n",
    "    for i in range(0,len(x_train),bs):\n",
    "        yield x_train[i:i+bs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a309354",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = partial(dl, x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "024f2fab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(f())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1038f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export \n",
    "class dataset():\n",
    "    def __init__(self, x, y):fc.store_attr()\n",
    "        \n",
    "    def __getitem__(self,i):\n",
    "        return self.x[i],self.y[i]\n",
    "    def __len__(self):\n",
    "        return len(self.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b76d9b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = dataset(x_train, y_train)\n",
    "valid_ds = dataset(x_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd15fef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6433e908",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class DL:\n",
    "    def __init__(self, ds, bs):fc.store_attr()\n",
    "        \n",
    "#     def __call__(self):\n",
    "#         for i in range(0,len(self.x),self.bs):\n",
    "#             yield self.x[i:i+bs], self.y[i:i+bs]\n",
    "    def __iter__(self):\n",
    "        for i in range(0,len(self.ds),self.bs):\n",
    "            yield self.ds[i:i+self.bs]\n",
    "    \n",
    "#     def __repr__(self):\n",
    "#         return f\"shape of x{self.ds[0].shape} \\n, shape of y{self.ds[1].shape} {self.bs} \"\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fe690f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DL(train_ds, bs = 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ffac1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_dl = DL(valid_ds, bs = 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5385d38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "459a9cf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 784]) torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "for xb, yb in train_dl:\n",
    "    print(xb.shape, yb.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "389cc63e",
   "metadata": {},
   "source": [
    "## Loss Function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc7e6f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export \n",
    "loss_func = F.cross_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4090aa04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (preds.argmax(1) == yb).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7459df11",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|\n",
    "def accuracy(preds, yb): return (preds.argmax(dim=1) == yb).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f36c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def report(loss, preds, yb,train=\"training\"): print(f' {train} Loss: {loss:.2f}, Accuracy: {accuracy(preds, yb):.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05290dc4",
   "metadata": {},
   "source": [
    "## Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a35d9147",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "model = nn.Sequential(nn.Linear(784,50), nn.ReLU(),nn.Linear(50,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac834c9a",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c9e43cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "epochs = 3\n",
    "lr = 0.1\n",
    "\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for xb, yb in train_dl:\n",
    "        preds = model(xb)\n",
    "#         print(preds.squeeze(dim=1).shape)\n",
    "#         print(yb.shape)\n",
    "        loss = loss_func(preds.squeeze(dim=1), yb)\n",
    "        loss.backward()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for params in model.parameters():\n",
    "                params -= lr * params.grad\n",
    "                \n",
    "            model.zero_grad()\n",
    "                \n",
    "        \n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3df929fa",
   "metadata": {},
   "source": [
    "## Optimiser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73549303",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list(model.parameters())[0].grad.data.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c240c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a08e2ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb96e00e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class opt():\n",
    "    def __init__(self, params , lr=0.5):self.params,self.lr=list(params),lr\n",
    "    \n",
    "    def zero_grad(self):\n",
    "        for p in self.params: p.grad.data.zero_() \n",
    "        \n",
    "        \n",
    "    \n",
    "    def step(self):\n",
    "        with torch.no_grad():\n",
    "            for p in self.params:\n",
    "                p -= self.lr * p.grad\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "475de779",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Optimizer():\n",
    "#     def __init__(self, params, lr=0.5): self.params,self.lr=list(params),lr\n",
    "\n",
    "#     def step(self):\n",
    "#         with torch.no_grad():\n",
    "#             for p in self.params: p -= p.grad * self.lr\n",
    "\n",
    "#     def zero_grad(self):\n",
    "#         for p in self.params: p.grad.data.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bddb14b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def fit(model, epochs=3, lr = 0.2):\n",
    "    \n",
    "    o = opt(model.parameters())\n",
    "#     o= Optimizer(model.parameters())\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        for xb, yb in train_dl:\n",
    "            preds = model(xb)\n",
    "    #         print(preds.squeeze(dim=1).shape)\n",
    "    #         print(yb.shape)\n",
    "            loss = loss_func(preds, yb)\n",
    "            \n",
    "            loss.backward()\n",
    "            o.step()\n",
    "            o.zero_grad()\n",
    "    \n",
    "        report(loss, preds, yb, \"training \")\n",
    "    \n",
    "        model.eval()    \n",
    "        with torch.no_grad():\n",
    "            for xb, yb in valid_dl:\n",
    "                preds = model(xb)\n",
    "                loss = loss_func(preds, yb)\n",
    "                \n",
    "#         print(preds.shape)\n",
    "        report(loss, preds, yb, \"validation \")\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce7923b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5fd32cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " training  Loss: 0.02, Accuracy: 1.00\n",
      " validation  Loss: 0.18, Accuracy: 0.97\n",
      " training  Loss: 0.01, Accuracy: 1.00\n",
      " validation  Loss: 0.18, Accuracy: 0.97\n",
      " training  Loss: 0.01, Accuracy: 1.00\n",
      " validation  Loss: 0.20, Accuracy: 0.97\n"
     ]
    }
   ],
   "source": [
    "fit(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ba4982",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6827dfb7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4113ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "from torch.utils.data import DataLoader, SequentialSampler, RandomSampler, BatchSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40a26b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide \n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe8cedc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
